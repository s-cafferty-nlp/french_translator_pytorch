{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiMlbUEPCSnQ"
      },
      "source": [
        "# Building A Translation Application from Scratch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Arrm-jnpLJku",
        "outputId": "8cc08e6e-4659-407e-895e-a42b5c362563"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n"
          ]
        }
      ],
      "source": [
        "! pip install sentencepiece\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWKusWVNCXZw"
      },
      "source": [
        "## 1. Getting dataset (22,000,000 English-French Translations)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFPuwHOzvyQJ"
      },
      "outputs": [],
      "source": [
        "# ! pip install kaggle\n",
        "# ! mkdir ~/.kaggle\n",
        "# ! cp kaggle.json ~/.kaggle/\n",
        "# ! chmod 600 ~/.kaggle/kaggle.json\n",
        "# ! kaggle datasets download dhruvildave/en-fr-translation-dataset\n",
        "# ! unzip /content/en-fr-translation-dataset.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6I4l9Z5ccHl"
      },
      "source": [
        "Some notes on this dataset: It's pretty messy and it's so large that it's hard to shuffle it."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-KtGI63hCoYi"
      },
      "source": [
        "## 2. Building a SentencePiece Tokenizer\n",
        "\n",
        "We could build separate vocabulary-based tokenizers for French and English, but this would be somewhat cumbersome. Let's try to build a shared byte-pair encoding tokenizer. This could be done from scratch, but the SentencePiece library is too convenient.\n",
        "\n",
        "Some things to consider: When working with subwords, we can make our model smaller and more efficient, but do we sacrifice accuracy? That's a good question. Even so, we can maintain punctuation and case, and better account for 'unknown' words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "K9WRXnHp8g2g"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "source_path = '/content/drive/MyDrive/NLP_2023/french_translation/en-fr.csv'\n",
        "\n",
        "source_path_2 = '/content/drive/MyDrive/NLP_2023/french_translation/english-french-common.csv'\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "dff = pd.read_csv(source_path, chunksize=500000)\n",
        "df2 = pd.read_csv(source_path_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dFBFWauo8l9X"
      },
      "outputs": [],
      "source": [
        "df = next(dff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Z_Cfn6a2cumg",
        "outputId": "e991af50-0d67-491c-8eab-59f99c59a45f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-772985c8-da78-45f6-be59-3788fa0f87d2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>323022</th>\n",
              "      <td>Vinevax Bio-dowel Fungicide Label crops Target...</td>\n",
              "      <td>Vinevax Bio-dowel Fongicide Cultures principal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>443483</th>\n",
              "      <td>Or Both orders of governments must make every ...</td>\n",
              "      <td>Ou Les deux ordres de gouvernement doivent fai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231454</th>\n",
              "      <td>Sylvain de Tonnancour James Holloway Senior Po...</td>\n",
              "      <td>Sylvain de Tonnancour James Holloway Conseille...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339808</th>\n",
              "      <td>Section 33 quality assurance processes used to...</td>\n",
              "      <td>Les processus d’assurance de la qualité prévus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255963</th>\n",
              "      <td>◦ New technology – Maximum application of exis...</td>\n",
              "      <td>◦ Nouvelle technologie – Application maximale ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226577</th>\n",
              "      <td>Find out now how to develop an e-business stra...</td>\n",
              "      <td>Vous apprendrez ici comment développer une str...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322724</th>\n",
              "      <td>Maturity - Indeterminate Growth Lentil has an ...</td>\n",
              "      <td>Maturité et croissance indéterminée La croissa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261621</th>\n",
              "      <td>Regardless of their merit or commercial value,...</td>\n",
              "      <td>Indépendamment de leurs qualités ou leur valeu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72252</th>\n",
              "      <td>Game</td>\n",
              "      <td>Jeu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457138</th>\n",
              "      <td>◦ See Chicken Section Table Eggs and Processed...</td>\n",
              "      <td>◦ Voir Salubrité des Aliments (Poulets) Oeufs ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-772985c8-da78-45f6-be59-3788fa0f87d2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-772985c8-da78-45f6-be59-3788fa0f87d2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-772985c8-da78-45f6-be59-3788fa0f87d2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                       en  \\\n",
              "323022  Vinevax Bio-dowel Fungicide Label crops Target...   \n",
              "443483  Or Both orders of governments must make every ...   \n",
              "231454  Sylvain de Tonnancour James Holloway\n",
              "Senior Po...   \n",
              "339808  Section 33 quality assurance processes used to...   \n",
              "255963  ◦ New technology – Maximum application of exis...   \n",
              "226577  Find out now how to develop an e-business stra...   \n",
              "322724  Maturity - Indeterminate Growth Lentil has an ...   \n",
              "261621  Regardless of their merit or commercial value,...   \n",
              "72252                                                Game   \n",
              "457138  ◦ See Chicken Section Table Eggs and Processed...   \n",
              "\n",
              "                                                       fr  \n",
              "323022  Vinevax Bio-dowel Fongicide Cultures principal...  \n",
              "443483  Ou Les deux ordres de gouvernement doivent fai...  \n",
              "231454  Sylvain de Tonnancour James Holloway\n",
              "Conseille...  \n",
              "339808  Les processus d’assurance de la qualité prévus...  \n",
              "255963  ◦ Nouvelle technologie – Application maximale ...  \n",
              "226577  Vous apprendrez ici comment développer une str...  \n",
              "322724  Maturité et croissance indéterminée La croissa...  \n",
              "261621  Indépendamment de leurs qualités ou leur valeu...  \n",
              "72252                                                 Jeu  \n",
              "457138  ◦ Voir Salubrité des Aliments (Poulets) Oeufs ...  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "-hLqeB4DdvLP",
        "outputId": "d31c493b-a4a3-4d7c-aa9f-3179268aae1a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1d173272-f8f1-48ca-b570-fd8b67a04f1f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>163745</th>\n",
              "      <td>Tom certainly had a lot of time to think about...</td>\n",
              "      <td>Tom avait certainement beaucoup de temps pour ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152876</th>\n",
              "      <td>There's a little bit of water in the glass.</td>\n",
              "      <td>Il y a un peu d'eau dans le verre.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164200</th>\n",
              "      <td>I don't know whether he'll come by train or by...</td>\n",
              "      <td>Je ne sais pas s'il viendra par le train ou en...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117546</th>\n",
              "      <td>Unfortunately he refused to come.</td>\n",
              "      <td>Malheureusement il a refusé de venir.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170088</th>\n",
              "      <td>We're going to invite Tom and Mary to our Hall...</td>\n",
              "      <td>Nous allons inviter Tom et Mary à notre fête d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24274</th>\n",
              "      <td>I should come, too.</td>\n",
              "      <td>Je devrais venir, aussi.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72223</th>\n",
              "      <td>Tom's family is in Boston.</td>\n",
              "      <td>La famille de Tom est à Boston.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69267</th>\n",
              "      <td>I went to the post office.</td>\n",
              "      <td>Je suis allé à la poste.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141020</th>\n",
              "      <td>I ran into a friend of mine on the bus.</td>\n",
              "      <td>Je suis tombée sur une amie à moi dans le bus.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7568</th>\n",
              "      <td>He is a writer.</td>\n",
              "      <td>Il est écrivain.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d173272-f8f1-48ca-b570-fd8b67a04f1f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d173272-f8f1-48ca-b570-fd8b67a04f1f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d173272-f8f1-48ca-b570-fd8b67a04f1f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                       en  \\\n",
              "163745  Tom certainly had a lot of time to think about...   \n",
              "152876        There's a little bit of water in the glass.   \n",
              "164200  I don't know whether he'll come by train or by...   \n",
              "117546                  Unfortunately he refused to come.   \n",
              "170088  We're going to invite Tom and Mary to our Hall...   \n",
              "24274                                 I should come, too.   \n",
              "72223                          Tom's family is in Boston.   \n",
              "69267                          I went to the post office.   \n",
              "141020            I ran into a friend of mine on the bus.   \n",
              "7568                                      He is a writer.   \n",
              "\n",
              "                                                       fr  \n",
              "163745  Tom avait certainement beaucoup de temps pour ...  \n",
              "152876                 Il y a un peu d'eau dans le verre.  \n",
              "164200  Je ne sais pas s'il viendra par le train ou en...  \n",
              "117546              Malheureusement il a refusé de venir.  \n",
              "170088  Nous allons inviter Tom et Mary à notre fête d...  \n",
              "24274                            Je devrais venir, aussi.  \n",
              "72223                     La famille de Tom est à Boston.  \n",
              "69267                            Je suis allé à la poste.  \n",
              "141020     Je suis tombée sur une amie à moi dans le bus.  \n",
              "7568                                     Il est écrivain.  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2 = df2.rename(columns={'English words/sentences':'en','French words/sentences':'fr'})\n",
        "df2.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wS4amUFaeadi",
        "outputId": "6905c3d8-b0e3-4738-8d70-2eac015d12fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "175621\n"
          ]
        }
      ],
      "source": [
        "print(len(df2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "oFB4QgsIeAcw",
        "outputId": "aaf21cd4-9614-4da5-d7aa-605fa2b34ad3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-844884ba-6d4a-4869-a900-5e5adfb79e66\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>97720</th>\n",
              "      <td>I'm sorry if I frightened you.</td>\n",
              "      <td>Je suis désolée si je vous ai effrayés.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177929</th>\n",
              "      <td>Welcome to our Region</td>\n",
              "      <td>De l'innovation solide comme le roc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30984</th>\n",
              "      <td>She got in the taxi.</td>\n",
              "      <td>Elle est montée dans un taxi.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155922</th>\n",
              "      <td>I really don't want to go to Boston with Tom.</td>\n",
              "      <td>Je ne veux vraiment pas aller à Boston avec Tom.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243341</th>\n",
              "      <td>Business Information by Sector Canadian Oil an...</td>\n",
              "      <td>Information d'affaires par secteur Industrie c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161185</th>\n",
              "      <td>And, when Canadians do venture outside their h...</td>\n",
              "      <td>En outre, lorsque les Canadiens quittent leur ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163247</th>\n",
              "      <td>I read in the newspaper that he had been murde...</td>\n",
              "      <td>J'ai lu dans le journal qu'il avait été assass...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64446</th>\n",
              "      <td>This question isn't easy.</td>\n",
              "      <td>Cette question n'est pas simple.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295991</th>\n",
              "      <td>While participants did not agree that the APF ...</td>\n",
              "      <td>Même si les participants ne croient pas que le...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8238</th>\n",
              "      <td>I wasn't hired.</td>\n",
              "      <td>On ne m'a pas embauché.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-844884ba-6d4a-4869-a900-5e5adfb79e66')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-844884ba-6d4a-4869-a900-5e5adfb79e66 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-844884ba-6d4a-4869-a900-5e5adfb79e66');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                       en  \\\n",
              "97720                      I'm sorry if I frightened you.   \n",
              "177929                              Welcome to our Region   \n",
              "30984                                She got in the taxi.   \n",
              "155922      I really don't want to go to Boston with Tom.   \n",
              "243341  Business Information by Sector Canadian Oil an...   \n",
              "161185  And, when Canadians do venture outside their h...   \n",
              "163247  I read in the newspaper that he had been murde...   \n",
              "64446                           This question isn't easy.   \n",
              "295991  While participants did not agree that the APF ...   \n",
              "8238                                      I wasn't hired.   \n",
              "\n",
              "                                                       fr  \n",
              "97720             Je suis désolée si je vous ai effrayés.  \n",
              "177929                De l'innovation solide comme le roc  \n",
              "30984                       Elle est montée dans un taxi.  \n",
              "155922   Je ne veux vraiment pas aller à Boston avec Tom.  \n",
              "243341  Information d'affaires par secteur Industrie c...  \n",
              "161185  En outre, lorsque les Canadiens quittent leur ...  \n",
              "163247  J'ai lu dans le journal qu'il avait été assass...  \n",
              "64446                    Cette question n'est pas simple.  \n",
              "295991  Même si les participants ne croient pas que le...  \n",
              "8238                              On ne m'a pas embauché.  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df3 = pd.concat([df.sample(175621), df2])\n",
        "df3.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n80j1Bwgeizp",
        "outputId": "b08f06c7-0b9d-4b5d-d60b-859e3c2ee0cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "351242\n"
          ]
        }
      ],
      "source": [
        "print(len(df3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "C-F1DWtg9pSX"
      },
      "outputs": [],
      "source": [
        "df3['en'] = df3['en'].astype('str')\n",
        "df3['fr'] = df3['fr'].astype('str')\n",
        "sample_text = list(df3['en'] + df3['fr'])\n",
        "\n",
        "with open(\"sample_text.txt\", \"w\") as output:\n",
        "    output.write(str((\"\\n\").join(sample_text)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uUWEaBiT99sg"
      },
      "outputs": [],
      "source": [
        "from sentencepiece import SentencePieceTrainer, SentencePieceProcessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o75bZDqE9zO1",
        "outputId": "b3aece8b-61f4-4510-dcf9-0d792115a967"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--input=/content/sample_text.txt --model_type=bpe --model_prefix=/content/drive/MyDrive/NLP_2023/french_translation/sentencepiece --vocab_size=10000 --pad_id=0 --unk_id=1 --bos_id=2 --eos_id=3\n"
          ]
        }
      ],
      "source": [
        "input_file = '/content/sample_text.txt'\n",
        "max_num_words = 10000\n",
        "model_type = 'bpe'\n",
        "model_prefix = '/content/drive/MyDrive/NLP_2023/french_translation/sentencepiece'\n",
        "pad_id = 0\n",
        "unk_id = 1\n",
        "bos_id = 2\n",
        "eos_id = 3\n",
        "\n",
        "sentencepiece_params = ' '.join([\n",
        "    '--input={}'.format(input_file),\n",
        "    '--model_type={}'.format(model_type),\n",
        "    '--model_prefix={}'.format(model_prefix),\n",
        "    '--vocab_size={}'.format(max_num_words),\n",
        "    '--pad_id={}'.format(pad_id),\n",
        "    '--unk_id={}'.format(unk_id),\n",
        "    '--bos_id={}'.format(bos_id),\n",
        "    '--eos_id={}'.format(eos_id)\n",
        "])\n",
        "print(sentencepiece_params)\n",
        "SentencePieceTrainer.train(sentencepiece_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsKUf7cTB0uY",
        "outputId": "22dc4d65-8879-4726-877c-d71166c0e287"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 10000 unique tokens.\n"
          ]
        }
      ],
      "source": [
        "sp = SentencePieceProcessor()\n",
        "sp.bos_token = '<start>'\n",
        "sp.eos_token = '<end>'\n",
        "sp.pad_token = '<pad>'\n",
        "sp.unk_token = '<unk>'\n",
        "sp.load(f\"{model_prefix}.model\")\n",
        "print('Found %s unique tokens.' % sp.get_piece_size())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlXPJCzvjo91"
      },
      "source": [
        "## Testing our tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msWAzlvFB4pg",
        "outputId": "b816b604-f24e-49bc-94c8-b20634e0c2bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['▁Je', '▁n', \"'\", 'avais', '▁aucune', '▁idée']\n",
            "[3186, 45, 9925, 3992, 4273, 4756]\n"
          ]
        }
      ],
      "source": [
        "original = \"Je n'avais aucune idée\"\n",
        "encoded_pieces = sp.encode_as_pieces(original)\n",
        "print(encoded_pieces)\n",
        "\n",
        "# or convert it to numeric id for downstream modeling\n",
        "encoded_ids = sp.encode_as_ids(original)\n",
        "print(encoded_ids)\n",
        "#'[3261, 45, 9924, 4030, 4298, 4774]'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXJJ5GzbCCcX",
        "outputId": "7a7042dc-185c-4743-ce97-8e6911dc89a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Je n'avais aucune idée\n",
            "Je n'avais aucune idée\n"
          ]
        }
      ],
      "source": [
        "decoded_pieces = sp.decode_pieces(encoded_pieces)\n",
        "print(decoded_pieces)\n",
        "\n",
        "# we can convert the numeric id back to the original text\n",
        "decoded_ids = sp.decode_ids(encoded_ids)\n",
        "print(decoded_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eZhfKjmE32W",
        "outputId": "5c49265d-cea1-4bc5-adfc-758497226dbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2, 1876, 3016, 138, 2045, 15, 9921, 70, 551, 665, 91, 449, 10, 42, 213, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "max_len = 50\n",
        "\n",
        "def encode_english(text, sp):\n",
        "  byte_pairs = sp.encode_as_ids(text)\n",
        "  enc_c = [sp.bos_id()] + list(byte_pairs) + [sp.pad_id()] * (max_len - len(list(byte_pairs)))\n",
        "  return enc_c[:max_len]\n",
        "\n",
        "sample_text = 'My name is Sean, and je suis un americain'\n",
        "print(encode_english(sample_text, sp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIlv4LOGGTbo",
        "outputId": "1e63a275-5f4b-4292-defc-26f519b1a64a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2, 1876, 3016, 138, 2045, 15, 9921, 70, 551, 665, 91, 449, 10, 42, 213, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ],
      "source": [
        "def encode_french(text, sp):\n",
        "    byte_pairs = sp.encode_as_ids(text)\n",
        "    enc_c = [sp.bos_id()] + list(byte_pairs) + [sp.eos_id()] + [sp.pad_id()] * (max_len - len(list(byte_pairs)))\n",
        "    return enc_c[:max_len]\n",
        "\n",
        "sample_text = 'My name is Sean, and je suis un americain'\n",
        "print(encode_french(sample_text, sp))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTPMCN3IgDa8"
      },
      "source": [
        "Finalizing our Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "P_CowgRtgGx6",
        "outputId": "951c51b9-2623-4768-ae4b-0e0ebc2a6b7f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3e352af7-467c-465b-9782-9269df895026\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>175616</th>\n",
              "      <td>Top-down economics never works, said Obama. \"T...</td>\n",
              "      <td>« L'économie en partant du haut vers le bas, ç...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175617</th>\n",
              "      <td>A carbon footprint is the amount of carbon dio...</td>\n",
              "      <td>Une empreinte carbone est la somme de pollutio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175618</th>\n",
              "      <td>Death is something that we're often discourage...</td>\n",
              "      <td>La mort est une chose qu'on nous décourage sou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175619</th>\n",
              "      <td>Since there are usually multiple websites on a...</td>\n",
              "      <td>Puisqu'il y a de multiples sites web sur chaqu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175620</th>\n",
              "      <td>If someone who doesn't know your background sa...</td>\n",
              "      <td>Si quelqu'un qui ne connaît pas vos antécédent...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e352af7-467c-465b-9782-9269df895026')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3e352af7-467c-465b-9782-9269df895026 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3e352af7-467c-465b-9782-9269df895026');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                       en  \\\n",
              "175616  Top-down economics never works, said Obama. \"T...   \n",
              "175617  A carbon footprint is the amount of carbon dio...   \n",
              "175618  Death is something that we're often discourage...   \n",
              "175619  Since there are usually multiple websites on a...   \n",
              "175620  If someone who doesn't know your background sa...   \n",
              "\n",
              "                                                       fr  \n",
              "175616  « L'économie en partant du haut vers le bas, ç...  \n",
              "175617  Une empreinte carbone est la somme de pollutio...  \n",
              "175618  La mort est une chose qu'on nous décourage sou...  \n",
              "175619  Puisqu'il y a de multiples sites web sur chaqu...  \n",
              "175620  Si quelqu'un qui ne connaît pas vos antécédent...  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df3.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ra0E4Ny5gXKF",
        "outputId": "d1a57afa-745b-4971-ed57-caf0e5df0f31"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7b57f8f2-764d-435c-9401-b9ef5c9f93cc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>fr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>108377</th>\n",
              "      <td>How long have you had this pain?</td>\n",
              "      <td>Depuis combien de temps as-tu cette douleur ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173827</th>\n",
              "      <td>Just because something is more expensive doesn...</td>\n",
              "      <td>Ce n'est pas parce que quelque chose est plus ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399596</th>\n",
              "      <td>Both treatments require tillage for incorporat...</td>\n",
              "      <td>Sécurité La sécurité constitue le facteur le p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>401767</th>\n",
              "      <td>The UV disinfection unit was originally instal...</td>\n",
              "      <td>Le système a coûté environ 7 000 $, ce qui com...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61438</th>\n",
              "      <td>I know Tom is colorblind.</td>\n",
              "      <td>Je sais que Tom est daltonien.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7b57f8f2-764d-435c-9401-b9ef5c9f93cc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7b57f8f2-764d-435c-9401-b9ef5c9f93cc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7b57f8f2-764d-435c-9401-b9ef5c9f93cc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                       en  \\\n",
              "108377                   How long have you had this pain?   \n",
              "173827  Just because something is more expensive doesn...   \n",
              "399596  Both treatments require tillage for incorporat...   \n",
              "401767  The UV disinfection unit was originally instal...   \n",
              "61438                           I know Tom is colorblind.   \n",
              "\n",
              "                                                       fr  \n",
              "108377      Depuis combien de temps as-tu cette douleur ?  \n",
              "173827  Ce n'est pas parce que quelque chose est plus ...  \n",
              "399596  Sécurité La sécurité constitue le facteur le p...  \n",
              "401767  Le système a coûté environ 7 000 $, ce qui com...  \n",
              "61438                      Je sais que Tom est daltonien.  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df4 = df3.sample(frac = 1)\n",
        "df4.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "XoI_aijHgpBc"
      },
      "outputs": [],
      "source": [
        "df4.to_csv('/content/drive/MyDrive/NLP_2023/french_translation/translation_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1WhvIldDAMA"
      },
      "source": [
        "### 3. Building a preprocessor and dataloader that accesses multiple files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "GKPSgFJ9oHVt"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset, IterableDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "L_zaDmuxXmH6"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "class CustomIterableDatasetv1(IterableDataset):\n",
        "\n",
        "    def __init__(self, filename, length):\n",
        "\n",
        "        #Store the filename in object's memory\n",
        "        self.filename = filename\n",
        "        self.len = length\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "\n",
        "    def preprocess(self, text, text2):\n",
        "\n",
        "        text_pp = torch.LongTensor(encode_english(text, sp))\n",
        "        text_pp2 = torch.LongTensor(encode_french(text2, sp))\n",
        "        \n",
        "        return text_pp, text_pp2\n",
        "\n",
        "    def line_mapper(self, line):\n",
        "        \n",
        "        text, text2 = self.preprocess(line[1], line[2])\n",
        "        \n",
        "        return text, text2\n",
        "       \n",
        "    def __iter__(self):\n",
        "\n",
        "        #Create an iterator\n",
        "        file_itr = open(self.filename)\n",
        "        reader = csv.reader(file_itr)\n",
        "\n",
        "        #Map each element using the line_mapper\n",
        "        mapped_itr = map(self.line_mapper, reader)\n",
        "        \n",
        "        return mapped_itr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "zgvPBbGhGpg_"
      },
      "outputs": [],
      "source": [
        "batch_size = 100\n",
        "source_path = '/content/drive/MyDrive/NLP_2023/french_translation/translation_data.csv'\n",
        "df = pd.read_csv(source_path)\n",
        "length = len(df)\n",
        "\n",
        "### No shuffle because it's an iterative loader\n",
        "train_loader = torch.utils.data.DataLoader(CustomIterableDatasetv1(source_path, length),\n",
        "                                           batch_size = batch_size,  \n",
        "                                           pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "JUvQ3Nm1jGDw"
      },
      "outputs": [],
      "source": [
        "### Function to create masks\n",
        "\n",
        "def create_masks(english, french_input, french_target):\n",
        "    \n",
        "    def subsequent_mask(size):\n",
        "        mask = torch.triu(torch.ones(size, size)).transpose(0, 1).type(dtype=torch.uint8)\n",
        "        return mask.unsqueeze(0)\n",
        "    \n",
        "    english_mask = english!=0   ## This makes a matrix of true and falses\n",
        "    english_mask = english_mask.to(device)\n",
        "    english_mask = english_mask.unsqueeze(1).unsqueeze(1)         # (batch_size, 1, 1, max_words)\n",
        "  \n",
        "\n",
        "    french_input_mask = french_input!=0\n",
        "    french_input_mask = french_input_mask.unsqueeze(1)  # (batch_size, 1, max_words)\n",
        "    french_input_mask = french_input_mask & subsequent_mask(french_input.size(-1)).type_as(french_input_mask.data) \n",
        "    french_input_mask = french_input_mask.unsqueeze(1) # (batch_size, 1, max_words, max_words)\n",
        "    french_target_mask = french_target!=0              # (batch_size, max_words)\n",
        "    \n",
        "    return english_mask, french_input_mask, french_target_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BZx5tIdjIR-"
      },
      "source": [
        "# Build Transformer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "KtxtezHljKBt"
      },
      "outputs": [],
      "source": [
        "class Embeddings(nn.Module):\n",
        "    \"\"\"\n",
        "    Initializes embeddings\n",
        "    Adds positional encoding\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, d_model, max_len = 50):\n",
        "        super(Embeddings, self).__init__()\n",
        "        self.d_model = d_model  ## This is basically how deep the model is, so the embeddings are going to be 512 numbers for each word.\n",
        "        self.embed = nn.Embedding(vocab_size, d_model)\n",
        "        self.pe = self.create_positinal_encoding(max_len, self.d_model)\n",
        "        self.dropout = nn.Dropout(0.1) \n",
        "        \n",
        "    def create_positinal_encoding(self, max_len, d_model):\n",
        "        pe = torch.zeros(max_len, d_model).to(device)\n",
        "        for pos in range(max_len):   # for each position of the word\n",
        "            for i in range(0, d_model, 2):   # for each dimension of the each position\n",
        "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
        "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
        "        pe = pe.unsqueeze(0)   # include the batch size\n",
        "        return pe\n",
        "        \n",
        "    def forward(self, encoded_words):\n",
        "        embedding = self.embed(encoded_words) * math.sqrt(self.d_model) ## To add more weight to embeddings\n",
        "        embedding += self.pe[:, :embedding.size(1)]   # pe will automatically be expanded with the same batch size as encoded_words\n",
        "        embedding = self.dropout(embedding) ## Isn't this the same dropout?\n",
        "        return embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Xvws9t0IjMJI"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    '''\n",
        "    Runs Embeddings through linear layer to create query, keys, and values\n",
        "    Divides q,k,v by heads\n",
        "    '''\n",
        "    def __init__(self, heads, d_model):\n",
        "        \n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        assert d_model % heads == 0\n",
        "        self.d_k = d_model // heads\n",
        "        self.heads = heads\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.query = nn.Linear(d_model, d_model)\n",
        "        self.key = nn.Linear(d_model, d_model)\n",
        "        self.value = nn.Linear(d_model, d_model)\n",
        "        self.concat = nn.Linear(d_model, d_model)\n",
        "        \n",
        "    def forward(self, query, key, value, mask):\n",
        "        \"\"\"\n",
        "        query, key, value of shape: (batch_size, max_len, 512)\n",
        "        mask of shape: (batch_size, 1, 1, max_words)\n",
        "        \"\"\"\n",
        "        # (batch_size, max_len, 512)\n",
        "        query = self.query(query)\n",
        "        key = self.key(key)        \n",
        "        value = self.value(value)   \n",
        "        \n",
        "        # (batch_size, max_len, 512) --> (batch_size, max_len, h, d_k) --> (batch_size, h, max_len, d_k)\n",
        "        query = query.view(query.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)   \n",
        "        key = key.view(key.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)  \n",
        "        value = value.view(value.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)  \n",
        "        \n",
        "        # (batch_size, h, max_len, d_k) matmul (batch_size, h, d_k, max_len) --> (batch_size, h, max_len, max_len)\n",
        "        scores = torch.matmul(query, key.permute(0,1,3,2)) / math.sqrt(query.size(-1))\n",
        "        scores = scores.masked_fill(mask == 0, -1e9)    # (batch_size, h, max_len, max_len)\n",
        "        weights = F.softmax(scores, dim = -1)           # (batch_size, h, max_len, max_len)\n",
        "        weights = self.dropout(weights)\n",
        "        \n",
        "        # (batch_size, h, max_len, max_len) matmul (batch_size, h, max_len, d_k) --> (batch_size, h, max_len, d_k)\n",
        "        context = torch.matmul(weights, value)\n",
        "        # (batch_size, h, max_len, d_k) --> (batch_size, max_len, h, d_k) --> (batch_size, max_len, h * d_k)\n",
        "        context = context.permute(0,2,1,3).contiguous().view(context.shape[0], -1, self.heads * self.d_k)\n",
        "        # (batch_size, max_len, h * d_k)\n",
        "        interacted = self.concat(context)\n",
        "        return interacted "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "7N-DmhNrjPO9"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    '''\n",
        "    This is a later linear layer, for adding more features.\n",
        "    '''\n",
        "    def __init__(self, d_model, middle_dim = 2048):\n",
        "        super(FeedForward, self).__init__()\n",
        "        \n",
        "        self.fc1 = nn.Linear(d_model, middle_dim)\n",
        "        self.fc2 = nn.Linear(middle_dim, d_model)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.fc1(x))\n",
        "        out = self.fc2(self.dropout(out))\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "8x4KAcs9jQ2h"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    '''\n",
        "    creates encoder layer\n",
        "    '''\n",
        "    def __init__(self, d_model, heads):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.layernorm = nn.LayerNorm(d_model)\n",
        "        self.self_multihead = MultiHeadAttention(heads, d_model)\n",
        "        self.feed_forward = FeedForward(d_model)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, embeddings, mask):\n",
        "        interacted = self.dropout(self.self_multihead(embeddings, embeddings, embeddings, mask))\n",
        "        interacted = self.layernorm(interacted + embeddings)\n",
        "        feed_forward_out = self.dropout(self.feed_forward(interacted))\n",
        "        encoded = self.layernorm(feed_forward_out + interacted)\n",
        "        return encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "rgX5SyL5jSS2"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, d_model, heads):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.layernorm = nn.LayerNorm(d_model)\n",
        "        self.self_multihead = MultiHeadAttention(heads, d_model)\n",
        "        self.src_multihead = MultiHeadAttention(heads, d_model)\n",
        "        self.feed_forward = FeedForward(d_model)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        \n",
        "    def forward(self, embeddings, encoded, src_mask, target_mask):\n",
        "        query = self.dropout(self.self_multihead(embeddings, embeddings, embeddings, target_mask))\n",
        "        query = self.layernorm(query + embeddings)\n",
        "        interacted = self.dropout(self.src_multihead(query, encoded, encoded, src_mask))\n",
        "        interacted = self.layernorm(interacted + query)\n",
        "        feed_forward_out = self.dropout(self.feed_forward(interacted))\n",
        "        decoded = self.layernorm(feed_forward_out + interacted)\n",
        "        return decoded\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "DPytRbDnjT4A"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    \n",
        "    def __init__(self, d_model, heads, num_layers):\n",
        "        super(Transformer, self).__init__()\n",
        "        \n",
        "        self.d_model = d_model\n",
        "        self.vocab_size = 10000\n",
        "        self.embed = Embeddings(self.vocab_size, d_model)\n",
        "        self.encoder = nn.ModuleList([EncoderLayer(d_model, heads) for _ in range(num_layers)])\n",
        "        self.decoder = nn.ModuleList([DecoderLayer(d_model, heads) for _ in range(num_layers)])\n",
        "        self.logit = nn.Linear(d_model, self.vocab_size)\n",
        "        \n",
        "    def encode(self, src_words, src_mask):\n",
        "        src_embeddings = self.embed(src_words)\n",
        "        for layer in self.encoder:\n",
        "            src_embeddings = layer(src_embeddings, src_mask)\n",
        "        return src_embeddings\n",
        "    \n",
        "    def decode(self, target_words, target_mask, src_embeddings, src_mask):\n",
        "        tgt_embeddings = self.embed(target_words)\n",
        "        for layer in self.decoder:\n",
        "            tgt_embeddings = layer(tgt_embeddings, src_embeddings, src_mask, target_mask)\n",
        "        return tgt_embeddings\n",
        "        \n",
        "    def forward(self, src_words, src_mask, target_words, target_mask):\n",
        "        encoded = self.encode(src_words, src_mask)\n",
        "        decoded = self.decode(target_words, target_mask, encoded, src_mask)\n",
        "        out = F.log_softmax(self.logit(decoded), dim = 2)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "IpkqVvn4jVp9"
      },
      "outputs": [],
      "source": [
        "class AdamWarmup:\n",
        "    \n",
        "    def __init__(self, model_size, warmup_steps, optimizer):\n",
        "        \n",
        "        self.model_size = model_size\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.optimizer = optimizer\n",
        "        self.current_step = 0\n",
        "        self.lr = 0\n",
        "        \n",
        "    def get_lr(self):\n",
        "        return self.model_size ** (-0.5) * min(self.current_step ** (-0.5), self.current_step * self.warmup_steps ** (-1.5))\n",
        "        \n",
        "    def step(self):\n",
        "        # Increment the number of steps each time we call the step function\n",
        "        self.current_step += 1\n",
        "        lr = self.get_lr()\n",
        "        for param_group in self.optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "        # update the learning rate\n",
        "        self.lr = lr\n",
        "        self.optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "djxd4c9DjXNC"
      },
      "outputs": [],
      "source": [
        "class LossWithLS(nn.Module):\n",
        "\n",
        "    def __init__(self, size, smooth):\n",
        "        super(LossWithLS, self).__init__()\n",
        "        self.criterion = nn.KLDivLoss(size_average=False, reduce=False)\n",
        "        self.confidence = 1.0 - smooth\n",
        "        self.smooth = smooth\n",
        "        self.size = size\n",
        "        \n",
        "    def forward(self, prediction, target, mask):\n",
        "        \"\"\"\n",
        "        prediction of shape: (batch_size, max_words, vocab_size)\n",
        "        target and mask of shape: (batch_size, max_words)\n",
        "        \"\"\"\n",
        "        prediction = prediction.view(-1, prediction.size(-1))   # (batch_size * max_words, vocab_size)\n",
        "        target = target.contiguous().view(-1)   # (batch_size * max_words)\n",
        "        mask = mask.float()\n",
        "        mask = mask.view(-1)       # (batch_size * max_words)\n",
        "        labels = prediction.data.clone()\n",
        "        labels.fill_(self.smooth / (self.size - 1))\n",
        "        labels.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
        "        loss = self.criterion(prediction, labels)    # (batch_size * max_words, vocab_size)\n",
        "        loss = (loss.sum(1) * mask).sum() / mask.sum()\n",
        "        return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsWKb3Mwjw4J",
        "outputId": "3caa944e-f03e-402f-ff38-562dcb8e8c4e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        }
      ],
      "source": [
        "d_model = 512\n",
        "heads = 8\n",
        "num_layers = 3\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "epochs = 8\n",
        "vocab_size = sp.vocab_size()\n",
        "    \n",
        "transformer = Transformer(d_model = d_model, heads = heads, num_layers = num_layers)\n",
        "transformer = transformer.to(device)\n",
        "adam_optimizer = torch.optim.Adam(transformer.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9)\n",
        "transformer_optimizer = AdamWarmup(model_size = d_model, warmup_steps = 4000, optimizer = adam_optimizer)\n",
        "criterion = LossWithLS(vocab_size, 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "CDYFeYe5j-lm"
      },
      "outputs": [],
      "source": [
        "def train(train_loader, transformer, criterion, epoch):\n",
        "    \n",
        "    transformer.train()\n",
        "    sum_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    for i, (english, french) in enumerate(train_loader):\n",
        "        \n",
        "        samples = english.shape[0]\n",
        "\n",
        "        # Move to device\n",
        "        english = english.to(device)\n",
        "        french = french.to(device)\n",
        "\n",
        "        # Prepare Target Data\n",
        "        french_input = french[:, :-1] ## Remove the <end> token\n",
        "        french_target = french[:, 1:] ## Remove the <start> token\n",
        "\n",
        "        # Create mask and add dimensions\n",
        "        english_mask, french_input_mask, french_target_mask = create_masks(english, french_input, french_target)\n",
        "\n",
        "        # Get the transformer outputs\n",
        "        out = transformer(english, english_mask, french_input, french_input_mask)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = criterion(out, french_target, french_target_mask)\n",
        "        \n",
        "        # Backprop\n",
        "        transformer_optimizer.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        transformer_optimizer.step()\n",
        "        \n",
        "        sum_loss += loss.item() * samples\n",
        "        count += samples\n",
        "        \n",
        "        if i % 100 == 0:\n",
        "            print(\"Epoch [{}][{}/{}]\\tLoss: {:.3f}\".format(epoch, i, len(train_loader), sum_loss/count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "6lq_Su5SkDKS"
      },
      "outputs": [],
      "source": [
        "def evaluate(transformer, english, english_mask, max_len):\n",
        "    \"\"\"\n",
        "    Performs Greedy Decoding with a batch size of 1\n",
        "    \"\"\"\n",
        "    transformer.eval()\n",
        "    start_token = sp.bos_id()\n",
        "    end_token = sp.eos_id()\n",
        "    encoded = transformer.encode(english, english_mask)\n",
        "    words = torch.LongTensor([[start_token]]).to(device)\n",
        "    \n",
        "    for step in range(max_len - 1):\n",
        "        size = words.shape[1]\n",
        "        target_mask = torch.triu(torch.ones(size, size)).transpose(0, 1).type(dtype=torch.uint8)\n",
        "        target_mask = target_mask.to(device).unsqueeze(0).unsqueeze(0)\n",
        "        decoded = transformer.decode(words, target_mask, encoded, english_mask)\n",
        "        predictions = transformer.logit(decoded[:, -1])\n",
        "        _, next_word = torch.max(predictions, dim = 1)\n",
        "        next_word = next_word.item()\n",
        "        if next_word == end_token:\n",
        "            break\n",
        "        words = torch.cat([words, torch.LongTensor([[next_word]]).to(device)], dim = 1)   # (1,step+2)\n",
        "        \n",
        "    # Construct Sentence\n",
        "    if words.dim() == 2:\n",
        "        words = words.squeeze(0)\n",
        "        words = words.tolist()\n",
        "        \n",
        "    sen_idx = [w for w in words if w not in {start_token}]\n",
        "    \n",
        "    sentence = sp.decode_ids(sen_idx)\n",
        "    \n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02Xn7x0TkuzC",
        "outputId": "0402b98c-5c2a-43b1-d661-2fef317cca34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [0][0/3513]\tLoss: 8.091\n",
            "Epoch [0][100/3513]\tLoss: 7.536\n",
            "Epoch [0][200/3513]\tLoss: 7.003\n",
            "Epoch [0][300/3513]\tLoss: 6.596\n",
            "Epoch [0][400/3513]\tLoss: 6.306\n",
            "Epoch [0][500/3513]\tLoss: 6.082\n",
            "Epoch [0][600/3513]\tLoss: 5.893\n",
            "Epoch [0][700/3513]\tLoss: 5.733\n",
            "Epoch [0][800/3513]\tLoss: 5.595\n",
            "Epoch [0][900/3513]\tLoss: 5.470\n",
            "Epoch [0][1000/3513]\tLoss: 5.356\n",
            "Epoch [0][1100/3513]\tLoss: 5.251\n",
            "Epoch [0][1200/3513]\tLoss: 5.155\n",
            "Epoch [0][1300/3513]\tLoss: 5.065\n",
            "Epoch [0][1400/3513]\tLoss: 4.979\n",
            "Epoch [0][1500/3513]\tLoss: 4.902\n",
            "Epoch [0][1600/3513]\tLoss: 4.828\n",
            "Epoch [0][1700/3513]\tLoss: 4.757\n",
            "Epoch [0][1800/3513]\tLoss: 4.692\n",
            "Epoch [0][1900/3513]\tLoss: 4.630\n",
            "Epoch [0][2000/3513]\tLoss: 4.571\n",
            "Epoch [0][2100/3513]\tLoss: 4.516\n",
            "Epoch [0][2200/3513]\tLoss: 4.463\n",
            "Epoch [0][2300/3513]\tLoss: 4.412\n",
            "Epoch [0][2400/3513]\tLoss: 4.365\n",
            "Epoch [0][2500/3513]\tLoss: 4.320\n",
            "Epoch [0][2600/3513]\tLoss: 4.276\n",
            "Epoch [0][2700/3513]\tLoss: 4.235\n",
            "Epoch [0][2800/3513]\tLoss: 4.195\n",
            "Epoch [0][2900/3513]\tLoss: 4.158\n",
            "Epoch [0][3000/3513]\tLoss: 4.122\n",
            "Epoch [0][3100/3513]\tLoss: 4.087\n",
            "Epoch [0][3200/3513]\tLoss: 4.055\n",
            "Epoch [0][3300/3513]\tLoss: 4.023\n",
            "Epoch [0][3400/3513]\tLoss: 3.992\n",
            "Epoch [0][3500/3513]\tLoss: 3.964\n",
            "Epoch [1][0/3513]\tLoss: 3.061\n",
            "Epoch [1][100/3513]\tLoss: 2.963\n",
            "Epoch [1][200/3513]\tLoss: 2.957\n",
            "Epoch [1][300/3513]\tLoss: 2.945\n",
            "Epoch [1][400/3513]\tLoss: 2.937\n",
            "Epoch [1][500/3513]\tLoss: 2.929\n",
            "Epoch [1][600/3513]\tLoss: 2.922\n",
            "Epoch [1][700/3513]\tLoss: 2.913\n",
            "Epoch [1][800/3513]\tLoss: 2.905\n",
            "Epoch [1][900/3513]\tLoss: 2.895\n",
            "Epoch [1][1000/3513]\tLoss: 2.886\n",
            "Epoch [1][1100/3513]\tLoss: 2.876\n",
            "Epoch [1][1200/3513]\tLoss: 2.867\n",
            "Epoch [1][1300/3513]\tLoss: 2.858\n",
            "Epoch [1][1400/3513]\tLoss: 2.848\n",
            "Epoch [1][1500/3513]\tLoss: 2.839\n",
            "Epoch [1][1600/3513]\tLoss: 2.831\n",
            "Epoch [1][1700/3513]\tLoss: 2.821\n",
            "Epoch [1][1800/3513]\tLoss: 2.813\n",
            "Epoch [1][1900/3513]\tLoss: 2.804\n",
            "Epoch [1][2000/3513]\tLoss: 2.797\n",
            "Epoch [1][2100/3513]\tLoss: 2.789\n",
            "Epoch [1][2200/3513]\tLoss: 2.781\n",
            "Epoch [1][2300/3513]\tLoss: 2.773\n",
            "Epoch [1][2400/3513]\tLoss: 2.765\n",
            "Epoch [1][2500/3513]\tLoss: 2.758\n",
            "Epoch [1][2600/3513]\tLoss: 2.750\n",
            "Epoch [1][2700/3513]\tLoss: 2.743\n",
            "Epoch [1][2800/3513]\tLoss: 2.735\n",
            "Epoch [1][2900/3513]\tLoss: 2.728\n",
            "Epoch [1][3000/3513]\tLoss: 2.721\n",
            "Epoch [1][3100/3513]\tLoss: 2.714\n",
            "Epoch [1][3200/3513]\tLoss: 2.708\n",
            "Epoch [1][3300/3513]\tLoss: 2.701\n",
            "Epoch [1][3400/3513]\tLoss: 2.694\n",
            "Epoch [1][3500/3513]\tLoss: 2.688\n",
            "Epoch [2][0/3513]\tLoss: 2.552\n",
            "Epoch [2][100/3513]\tLoss: 2.463\n",
            "Epoch [2][200/3513]\tLoss: 2.455\n",
            "Epoch [2][300/3513]\tLoss: 2.447\n",
            "Epoch [2][400/3513]\tLoss: 2.443\n",
            "Epoch [2][500/3513]\tLoss: 2.437\n",
            "Epoch [2][600/3513]\tLoss: 2.433\n",
            "Epoch [2][700/3513]\tLoss: 2.427\n",
            "Epoch [2][800/3513]\tLoss: 2.424\n",
            "Epoch [2][900/3513]\tLoss: 2.418\n",
            "Epoch [2][1000/3513]\tLoss: 2.414\n",
            "Epoch [2][1100/3513]\tLoss: 2.410\n",
            "Epoch [2][1200/3513]\tLoss: 2.406\n",
            "Epoch [2][1300/3513]\tLoss: 2.403\n",
            "Epoch [2][1400/3513]\tLoss: 2.398\n",
            "Epoch [2][1500/3513]\tLoss: 2.394\n",
            "Epoch [2][1600/3513]\tLoss: 2.391\n",
            "Epoch [2][1700/3513]\tLoss: 2.387\n",
            "Epoch [2][1800/3513]\tLoss: 2.384\n",
            "Epoch [2][1900/3513]\tLoss: 2.380\n",
            "Epoch [2][2000/3513]\tLoss: 2.378\n",
            "Epoch [2][2100/3513]\tLoss: 2.374\n",
            "Epoch [2][2200/3513]\tLoss: 2.372\n",
            "Epoch [2][2300/3513]\tLoss: 2.368\n",
            "Epoch [2][2400/3513]\tLoss: 2.365\n",
            "Epoch [2][2500/3513]\tLoss: 2.361\n",
            "Epoch [2][2600/3513]\tLoss: 2.357\n",
            "Epoch [2][2700/3513]\tLoss: 2.354\n",
            "Epoch [2][2800/3513]\tLoss: 2.351\n",
            "Epoch [2][2900/3513]\tLoss: 2.348\n",
            "Epoch [2][3000/3513]\tLoss: 2.345\n",
            "Epoch [2][3100/3513]\tLoss: 2.342\n",
            "Epoch [2][3200/3513]\tLoss: 2.339\n",
            "Epoch [2][3300/3513]\tLoss: 2.336\n",
            "Epoch [2][3400/3513]\tLoss: 2.333\n",
            "Epoch [2][3500/3513]\tLoss: 2.330\n",
            "Epoch [3][0/3513]\tLoss: 2.309\n",
            "Epoch [3][100/3513]\tLoss: 2.227\n",
            "Epoch [3][200/3513]\tLoss: 2.221\n",
            "Epoch [3][300/3513]\tLoss: 2.217\n",
            "Epoch [3][400/3513]\tLoss: 2.216\n",
            "Epoch [3][500/3513]\tLoss: 2.212\n",
            "Epoch [3][600/3513]\tLoss: 2.210\n",
            "Epoch [3][700/3513]\tLoss: 2.206\n",
            "Epoch [3][800/3513]\tLoss: 2.204\n",
            "Epoch [3][900/3513]\tLoss: 2.201\n",
            "Epoch [3][1000/3513]\tLoss: 2.199\n",
            "Epoch [3][1100/3513]\tLoss: 2.197\n",
            "Epoch [3][1200/3513]\tLoss: 2.195\n",
            "Epoch [3][1300/3513]\tLoss: 2.193\n",
            "Epoch [3][1400/3513]\tLoss: 2.190\n",
            "Epoch [3][1500/3513]\tLoss: 2.189\n",
            "Epoch [3][1600/3513]\tLoss: 2.187\n",
            "Epoch [3][1700/3513]\tLoss: 2.184\n",
            "Epoch [3][1800/3513]\tLoss: 2.183\n",
            "Epoch [3][1900/3513]\tLoss: 2.181\n",
            "Epoch [3][2000/3513]\tLoss: 2.180\n",
            "Epoch [3][2100/3513]\tLoss: 2.178\n",
            "Epoch [3][2200/3513]\tLoss: 2.177\n",
            "Epoch [3][2300/3513]\tLoss: 2.174\n",
            "Epoch [3][2400/3513]\tLoss: 2.173\n",
            "Epoch [3][2500/3513]\tLoss: 2.170\n",
            "Epoch [3][2600/3513]\tLoss: 2.168\n",
            "Epoch [3][2700/3513]\tLoss: 2.166\n",
            "Epoch [3][2800/3513]\tLoss: 2.164\n",
            "Epoch [3][2900/3513]\tLoss: 2.162\n",
            "Epoch [3][3000/3513]\tLoss: 2.160\n",
            "Epoch [3][3100/3513]\tLoss: 2.159\n",
            "Epoch [3][3200/3513]\tLoss: 2.157\n",
            "Epoch [3][3300/3513]\tLoss: 2.155\n",
            "Epoch [3][3400/3513]\tLoss: 2.153\n",
            "Epoch [3][3500/3513]\tLoss: 2.152\n",
            "Epoch [4][0/3513]\tLoss: 2.163\n",
            "Epoch [4][100/3513]\tLoss: 2.092\n",
            "Epoch [4][200/3513]\tLoss: 2.086\n",
            "Epoch [4][300/3513]\tLoss: 2.082\n",
            "Epoch [4][400/3513]\tLoss: 2.083\n",
            "Epoch [4][500/3513]\tLoss: 2.080\n",
            "Epoch [4][600/3513]\tLoss: 2.079\n",
            "Epoch [4][700/3513]\tLoss: 2.075\n",
            "Epoch [4][800/3513]\tLoss: 2.075\n",
            "Epoch [4][900/3513]\tLoss: 2.072\n",
            "Epoch [4][1000/3513]\tLoss: 2.070\n",
            "Epoch [4][1100/3513]\tLoss: 2.069\n",
            "Epoch [4][1200/3513]\tLoss: 2.068\n",
            "Epoch [4][1300/3513]\tLoss: 2.067\n",
            "Epoch [4][1400/3513]\tLoss: 2.065\n",
            "Epoch [4][1500/3513]\tLoss: 2.063\n",
            "Epoch [4][1600/3513]\tLoss: 2.062\n",
            "Epoch [4][1700/3513]\tLoss: 2.061\n",
            "Epoch [4][1800/3513]\tLoss: 2.060\n",
            "Epoch [4][1900/3513]\tLoss: 2.059\n",
            "Epoch [4][2000/3513]\tLoss: 2.058\n",
            "Epoch [4][2100/3513]\tLoss: 2.057\n",
            "Epoch [4][2200/3513]\tLoss: 2.056\n",
            "Epoch [4][2300/3513]\tLoss: 2.054\n",
            "Epoch [4][2400/3513]\tLoss: 2.053\n",
            "Epoch [4][2500/3513]\tLoss: 2.051\n",
            "Epoch [4][2600/3513]\tLoss: 2.050\n",
            "Epoch [4][2700/3513]\tLoss: 2.049\n",
            "Epoch [4][2800/3513]\tLoss: 2.047\n",
            "Epoch [4][2900/3513]\tLoss: 2.046\n",
            "Epoch [4][3000/3513]\tLoss: 2.044\n",
            "Epoch [4][3100/3513]\tLoss: 2.043\n",
            "Epoch [4][3200/3513]\tLoss: 2.042\n",
            "Epoch [4][3300/3513]\tLoss: 2.040\n",
            "Epoch [4][3400/3513]\tLoss: 2.039\n",
            "Epoch [4][3500/3513]\tLoss: 2.038\n",
            "Epoch [5][0/3513]\tLoss: 2.112\n",
            "Epoch [5][100/3513]\tLoss: 1.999\n",
            "Epoch [5][200/3513]\tLoss: 1.993\n",
            "Epoch [5][300/3513]\tLoss: 1.991\n",
            "Epoch [5][400/3513]\tLoss: 1.992\n",
            "Epoch [5][500/3513]\tLoss: 1.988\n",
            "Epoch [5][600/3513]\tLoss: 1.987\n",
            "Epoch [5][700/3513]\tLoss: 1.984\n",
            "Epoch [5][800/3513]\tLoss: 1.984\n",
            "Epoch [5][900/3513]\tLoss: 1.981\n",
            "Epoch [5][1000/3513]\tLoss: 1.980\n",
            "Epoch [5][1100/3513]\tLoss: 1.979\n",
            "Epoch [5][1200/3513]\tLoss: 1.978\n",
            "Epoch [5][1300/3513]\tLoss: 1.978\n",
            "Epoch [5][1400/3513]\tLoss: 1.976\n",
            "Epoch [5][1500/3513]\tLoss: 1.975\n",
            "Epoch [5][1600/3513]\tLoss: 1.975\n",
            "Epoch [5][1700/3513]\tLoss: 1.973\n",
            "Epoch [5][1800/3513]\tLoss: 1.973\n",
            "Epoch [5][1900/3513]\tLoss: 1.972\n",
            "Epoch [5][2000/3513]\tLoss: 1.972\n",
            "Epoch [5][2100/3513]\tLoss: 1.971\n",
            "Epoch [5][2200/3513]\tLoss: 1.970\n",
            "Epoch [5][2300/3513]\tLoss: 1.969\n",
            "Epoch [5][2400/3513]\tLoss: 1.968\n",
            "Epoch [5][2500/3513]\tLoss: 1.967\n",
            "Epoch [5][2600/3513]\tLoss: 1.965\n",
            "Epoch [5][2700/3513]\tLoss: 1.964\n",
            "Epoch [5][2800/3513]\tLoss: 1.963\n",
            "Epoch [5][2900/3513]\tLoss: 1.962\n",
            "Epoch [5][3000/3513]\tLoss: 1.961\n",
            "Epoch [5][3100/3513]\tLoss: 1.960\n",
            "Epoch [5][3200/3513]\tLoss: 1.960\n",
            "Epoch [5][3300/3513]\tLoss: 1.959\n",
            "Epoch [5][3400/3513]\tLoss: 1.958\n",
            "Epoch [5][3500/3513]\tLoss: 1.957\n",
            "Epoch [6][0/3513]\tLoss: 2.006\n",
            "Epoch [6][100/3513]\tLoss: 1.927\n",
            "Epoch [6][200/3513]\tLoss: 1.920\n",
            "Epoch [6][300/3513]\tLoss: 1.918\n",
            "Epoch [6][400/3513]\tLoss: 1.920\n",
            "Epoch [6][500/3513]\tLoss: 1.917\n",
            "Epoch [6][600/3513]\tLoss: 1.916\n",
            "Epoch [6][700/3513]\tLoss: 1.913\n",
            "Epoch [6][800/3513]\tLoss: 1.914\n",
            "Epoch [6][900/3513]\tLoss: 1.912\n",
            "Epoch [6][1000/3513]\tLoss: 1.911\n",
            "Epoch [6][1100/3513]\tLoss: 1.910\n",
            "Epoch [6][1200/3513]\tLoss: 1.910\n",
            "Epoch [6][1300/3513]\tLoss: 1.909\n",
            "Epoch [6][1400/3513]\tLoss: 1.908\n",
            "Epoch [6][1500/3513]\tLoss: 1.908\n",
            "Epoch [6][1600/3513]\tLoss: 1.907\n",
            "Epoch [6][1700/3513]\tLoss: 1.906\n",
            "Epoch [6][1800/3513]\tLoss: 1.906\n",
            "Epoch [6][1900/3513]\tLoss: 1.905\n",
            "Epoch [6][2000/3513]\tLoss: 1.905\n",
            "Epoch [6][2100/3513]\tLoss: 1.905\n",
            "Epoch [6][2200/3513]\tLoss: 1.904\n",
            "Epoch [6][2300/3513]\tLoss: 1.903\n",
            "Epoch [6][2400/3513]\tLoss: 1.902\n",
            "Epoch [6][2500/3513]\tLoss: 1.901\n",
            "Epoch [6][2600/3513]\tLoss: 1.900\n",
            "Epoch [6][2700/3513]\tLoss: 1.900\n",
            "Epoch [6][2800/3513]\tLoss: 1.898\n",
            "Epoch [6][2900/3513]\tLoss: 1.898\n",
            "Epoch [6][3000/3513]\tLoss: 1.897\n",
            "Epoch [6][3100/3513]\tLoss: 1.896\n",
            "Epoch [6][3200/3513]\tLoss: 1.896\n",
            "Epoch [6][3300/3513]\tLoss: 1.895\n",
            "Epoch [6][3400/3513]\tLoss: 1.894\n",
            "Epoch [6][3500/3513]\tLoss: 1.894\n",
            "Epoch [7][0/3513]\tLoss: 1.951\n",
            "Epoch [7][100/3513]\tLoss: 1.872\n",
            "Epoch [7][200/3513]\tLoss: 1.866\n",
            "Epoch [7][300/3513]\tLoss: 1.864\n",
            "Epoch [7][400/3513]\tLoss: 1.865\n",
            "Epoch [7][500/3513]\tLoss: 1.863\n",
            "Epoch [7][600/3513]\tLoss: 1.862\n",
            "Epoch [7][700/3513]\tLoss: 1.859\n",
            "Epoch [7][800/3513]\tLoss: 1.860\n",
            "Epoch [7][900/3513]\tLoss: 1.858\n",
            "Epoch [7][1000/3513]\tLoss: 1.857\n",
            "Epoch [7][1100/3513]\tLoss: 1.856\n",
            "Epoch [7][1200/3513]\tLoss: 1.856\n",
            "Epoch [7][1300/3513]\tLoss: 1.855\n",
            "Epoch [7][1400/3513]\tLoss: 1.854\n",
            "Epoch [7][1500/3513]\tLoss: 1.854\n",
            "Epoch [7][1600/3513]\tLoss: 1.853\n",
            "Epoch [7][1700/3513]\tLoss: 1.852\n",
            "Epoch [7][1800/3513]\tLoss: 1.853\n",
            "Epoch [7][1900/3513]\tLoss: 1.852\n",
            "Epoch [7][2000/3513]\tLoss: 1.852\n",
            "Epoch [7][2100/3513]\tLoss: 1.851\n",
            "Epoch [7][2200/3513]\tLoss: 1.851\n",
            "Epoch [7][2300/3513]\tLoss: 1.850\n",
            "Epoch [7][2400/3513]\tLoss: 1.850\n",
            "Epoch [7][2500/3513]\tLoss: 1.849\n",
            "Epoch [7][2600/3513]\tLoss: 1.848\n",
            "Epoch [7][2700/3513]\tLoss: 1.847\n",
            "Epoch [7][2800/3513]\tLoss: 1.846\n",
            "Epoch [7][2900/3513]\tLoss: 1.846\n",
            "Epoch [7][3000/3513]\tLoss: 1.845\n",
            "Epoch [7][3100/3513]\tLoss: 1.845\n",
            "Epoch [7][3200/3513]\tLoss: 1.844\n",
            "Epoch [7][3300/3513]\tLoss: 1.844\n",
            "Epoch [7][3400/3513]\tLoss: 1.843\n",
            "Epoch [7][3500/3513]\tLoss: 1.843\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(epochs):\n",
        "    \n",
        "    train(train_loader, transformer, criterion, epoch)\n",
        "    \n",
        "    state = {'epoch': epoch, 'transformer': transformer, 'transformer_optimizer': transformer_optimizer}\n",
        "    torch.save(state, '/content/drive/MyDrive/NLP_2023/french_translation/checkpoint_big_' + str(epoch) + '.pth.tar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "bFwwWOiz--sn"
      },
      "outputs": [],
      "source": [
        "checkpoint = torch.load('/content/drive/MyDrive/NLP_2023/french_translation/checkpoint_big_7.pth.tar')\n",
        "transformer = checkpoint['transformer']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oP-Tinsvk0KF",
        "outputId": "8efe3510-206c-4984-b730-18dd8e0be4e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "English: Hello, how are you today?\n",
            "Eh bien aujourd'hui, comment êtes-vous ?\n",
            "\n",
            "English: Excellent! The translation model seems to work!\n",
            "Le modèle semble traduite !\n",
            "\n",
            "English: Clearly, it's far from perfect.\n",
            "Il est loin parfaitement loin d'être parfait.\n",
            "\n",
            "English: But it sort of works I think.\n",
            "Mais je pense que ça fonctionne.\n",
            "\n",
            "English: And that's pretty good for only three hundred thousand data points.\n",
            "Et trois points de pourcentage, les données de l'ordre de trois mille points de vente.\n",
            "\n",
            "English: Let's try it with simpler sentences.\n",
            "Essayons de simplifier les phrases.\n",
            "\n",
            "English: I am a robot.\n",
            "Je suis un robot.\n",
            "\n",
            "English: I am from Japan.\n",
            "Je viens du Japon.\n",
            "\n",
            "English: I dance every day.\n",
            "Je danse tous les jours.\n",
            "\n",
            "English: And I like to eat pasta.\n",
            "Et j'aime manger des pâtes.\n",
            "\n",
            "English: As a basic translator, it's quite effective.\n",
            "En tant que c'est un traducteur de base efficace.\n",
            "\n",
            "English: Let's try it with more complex sentences.\n",
            "Essayons de plus complexes avec ça.\n",
            "\n",
            "English: Here's a sentence from the magazine The Economist.\n",
            "Voici une phrase de magazine.\n",
            "\n",
            "English: Ever since it was founded in 1944, the imf has had to get used to reinventing itself. Today, however, it faces an identity crisis like none before. \n",
            "Aujourd'hui, il n'a pas eu de crise de crise en 1944, mais il n'a pas eu d'impression d'être l'impression\n",
            "\n",
            "English: Well, it doesn't really work great.\n",
            "Eh bien, ça ne fonctionne pas vraiment.\n",
            "\n",
            "English: But, it's pretty good considering the limitations of the data set.\n",
            "Mais il est plutôt bon de déterminer les limites des données.\n",
            "\n",
            "English: Anyway, have a nice day, my love.\n",
            "N'importe quel jour, mon amour a une belle journée.\n",
            "\n",
            "English: Goodbye!\n",
            "Bonne au revoir !\n",
            "\n",
            "English: quit\n"
          ]
        }
      ],
      "source": [
        "while(1):\n",
        "    english = input(\"English: \") \n",
        "    if english == 'quit':\n",
        "        break\n",
        "    english = encode_english(english, sp)\n",
        "    english = torch.LongTensor(english).to(device).unsqueeze(0)\n",
        "    english_mask = (english!=0).to(device).unsqueeze(1).unsqueeze(1)  \n",
        "    sentence = evaluate(transformer, english, english_mask, int(40))\n",
        "    print(sentence+'\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5cBsDp2s5MU"
      },
      "source": [
        "## Conclusion: \n",
        "\n",
        "Byte-Pair encoding preserves the punctuation and produces pretty good results for morphologically complex languages like French. \n",
        "\n",
        "Because we're using an iterator to serve our data, we're losing the shuffling capabilities of the data loader. This means that shuffling has to occur in preprocessing. "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
